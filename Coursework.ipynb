{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamUWE1/AI_Submission/blob/main/Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6uPkeRsBM0w",
        "outputId": "aea78113-c8ac-4e47-995e-bb15c1fb49b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## Mount drive, imports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!unzip '/content/gdrive/MyDrive/Coursework_dataset.zip' > /dev/null\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Variables\n",
        "\n",
        "data_dir = 'Coursework_dataset'\n",
        "\n",
        "n_epochs = 10\n",
        "n_epochs2 = 15\n",
        "n_epochs3 = 30\n",
        "n_epochs4 = 50\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "image_res = 112\n",
        "image_res2 = 164\n",
        "image_res3 = 256\n",
        "\n",
        "numberOfClasses = 5\n",
        "\n",
        "lr1 = 0.003\n",
        "lr2 = 0.03\n",
        "lr3 = 0.1\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(image_res), \n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "transform_2 = transforms.Compose([transforms.Resize(image_res),\n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.RandomRotation(5),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "transform_3 = transforms.Compose([transforms.Resize(image_res),\n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.GrayScale(),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
        "val_data = datasets.ImageFolder(data_dir + '/validate', transform=transform)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "BsEjcd34gTJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfRCWpPPtDkF"
      },
      "source": [
        "#MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZgX-FnOagVj"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgpt-tals8K0",
        "outputId": "794d876a-4be5-44ad-ff30-5d77564fc3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier(\n",
            "  (fc1): Linear(in_features=37632, out_features=2048, bias=True)\n",
            "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "input_size = image_res * image_res * 3\n",
        "                                                                   \n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        hidden_1 = 2048\n",
        "        hidden_2 = 1024\n",
        "        hidden_3 = 512\n",
        "        \n",
        "        self.fc1 = nn.Linear(input_size, hidden_1)\n",
        "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
        "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
        "        self.fc4 = nn.Linear(hidden_3, numberOfClasses) \n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, input_size)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1) \n",
        "        return x\n",
        "\n",
        "model = Classifier()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9sUALf9s_oz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbGHS7FAtCIT",
        "outputId": "b94b5637-5e9c-4e35-db87-7f511c35134c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 13271.723676 \tValidation Loss: 4461.799630\n",
            "Validation loss decreased (inf --> 4461.799630).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 3835.998186 \tValidation Loss: 24.588249\n",
            "Validation loss decreased (4461.799630 --> 24.588249).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 298.473482 \tValidation Loss: 6.071104\n",
            "Validation loss decreased (24.588249 --> 6.071104).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 196.489774 \tValidation Loss: 1.590789\n",
            "Validation loss decreased (6.071104 --> 1.590789).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 169.663271 \tValidation Loss: 1.593100\n",
            "Epoch: 6 \tTraining Loss: 2686.303628 \tValidation Loss: 1.595685\n",
            "Epoch: 7 \tTraining Loss: 1148.680988 \tValidation Loss: 1.590016\n",
            "Validation loss decreased (1.590789 --> 1.590016).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 134.882309 \tValidation Loss: 1.591078\n",
            "Epoch: 9 \tTraining Loss: 1.595151 \tValidation Loss: 1.595031\n",
            "Epoch: 10 \tTraining Loss: 1.617386 \tValidation Loss: 1.593143\n",
            "Epoch: 11 \tTraining Loss: 727.259858 \tValidation Loss: 1.591723\n",
            "Epoch: 12 \tTraining Loss: 1.600356 \tValidation Loss: 1.590057\n",
            "Epoch: 13 \tTraining Loss: 1.594610 \tValidation Loss: 1.592294\n",
            "Epoch: 14 \tTraining Loss: 1.599772 \tValidation Loss: 1.590681\n",
            "Epoch: 15 \tTraining Loss: 1.601048 \tValidation Loss: 1.593142\n",
            "Epoch: 16 \tTraining Loss: 1.589205 \tValidation Loss: 1.590244\n",
            "Epoch: 17 \tTraining Loss: 1.598099 \tValidation Loss: 1.589753\n",
            "Validation loss decreased (1.590016 --> 1.589753).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 1.598501 \tValidation Loss: 1.589990\n",
            "Epoch: 19 \tTraining Loss: 1.603210 \tValidation Loss: 1.593840\n",
            "Epoch: 20 \tTraining Loss: 1.598103 \tValidation Loss: 1.590948\n",
            "Epoch: 21 \tTraining Loss: 1.898870 \tValidation Loss: 1.589560\n",
            "Validation loss decreased (1.589753 --> 1.589560).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 1.600721 \tValidation Loss: 1.592537\n",
            "Epoch: 23 \tTraining Loss: 1.602148 \tValidation Loss: 1.590319\n",
            "Epoch: 24 \tTraining Loss: 1.597491 \tValidation Loss: 1.590866\n",
            "Epoch: 25 \tTraining Loss: 1.601172 \tValidation Loss: 1.589758\n",
            "Epoch: 26 \tTraining Loss: 1.599930 \tValidation Loss: 1.592000\n",
            "Epoch: 27 \tTraining Loss: 1.598663 \tValidation Loss: 1.593369\n",
            "Epoch: 28 \tTraining Loss: 1.600760 \tValidation Loss: 1.591995\n",
            "Epoch: 29 \tTraining Loss: 1.597425 \tValidation Loss: 1.591396\n",
            "Epoch: 30 \tTraining Loss: 1.600721 \tValidation Loss: 1.594515\n"
          ]
        }
      ],
      "source": [
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() \n",
        "    for data, target in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        " \n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_MLP_model.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_MLP_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dJzzfvtJZZDS",
        "outputId": "1738557f-e863-4d7c-c41d-c3c7df347a62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd4d46bc490>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vECtPm1oZbF6",
        "outputId": "4dacb3c0-bc02-4de1-9459-ee57c72e351e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-02788fb11f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MLP_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MLP_model.pt'"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('CW_MLP_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1YAFUzBfZehq"
      },
      "outputs": [],
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "\n",
        "    for i in range(5):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VqTBCfwtHMF"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eK4Ct5C71Df"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULVhyRMG8ebo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "\n",
        "        self.fc2 = nn.Linear(500, number_classes) \n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzC3tWGG8wcB"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm0TBami86zG"
      },
      "outputs": [],
      "source": [
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_CNN_model.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_CNN_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0YSlaMU8-yE"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KET3rDfU9Dqr"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('CW_CNN_model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BAnUrKRtPMD"
      },
      "source": [
        "#TL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, numberOfClasses)\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "oV5Jw3eTOTAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ],
      "metadata": {
        "id": "kjsHFceGpZO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss_min = np.Inf\n",
        "\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() \n",
        "    for data, target in train_loader:\n",
        "\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_resnet18_model_fine_tune_aug.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_resnet18_model_fine_tune_aug.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "id": "YZUilYlzpbwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "id": "0ze50KwWpeL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('CW_resnet18_model_fine_tune_aug.pt'))"
      ],
      "metadata": {
        "id": "yJOHp7yHpgx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (class_total[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "OPYaqPYTppO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Coursework.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr2IZw5fMbonsthMC3HRNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}