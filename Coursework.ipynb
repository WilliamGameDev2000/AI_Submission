{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamUWE1/AI_Submission/blob/main/Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6uPkeRsBM0w",
        "outputId": "d8eabe2a-adb6-45cf-cf4e-96aae2cf285b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## Mount drive, imports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!unzip '/content/gdrive/MyDrive/Coursework_dataset.zip' > /dev/null\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Variables\n",
        "\n",
        "data_dir = 'Coursework_dataset'\n",
        "\n",
        "n_epochs = 10\n",
        "n_epochs2 = 15\n",
        "n_epochs3 = 30\n",
        "n_epochs4 = 50\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "image_res = 112\n",
        "image_res2 = 164\n",
        "image_res3 = 256\n",
        "\n",
        "numberOfClasses = 5\n",
        "\n",
        "lr1 = 0.003\n",
        "lr2 = 0.03\n",
        "lr3 = 0.1\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(image_res), \n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "transform_2 = transforms.Compose([transforms.Resize(image_res),\n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.RandomRotation(5),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "transform_3 = transforms.Compose([transforms.Resize(image_res),\n",
        "                                transforms.CenterCrop(image_res),\n",
        "                                transforms.Grayscale(),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                     [0.5, 0.5, 0.5])])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=transform)\n",
        "val_data = datasets.ImageFolder(data_dir + '/validate', transform=transform)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "BsEjcd34gTJ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfRCWpPPtDkF"
      },
      "source": [
        "#MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZZgX-FnOagVj"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgpt-tals8K0"
      },
      "outputs": [],
      "source": [
        "input_size = image_res * image_res * 3\n",
        "                                                                   \n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        hidden_1 = 2048\n",
        "        hidden_2 = 1024\n",
        "        hidden_3 = 512\n",
        "        \n",
        "        self.fc1 = nn.Linear(input_size, hidden_1)\n",
        "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
        "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
        "        self.fc4 = nn.Linear(hidden_3, numberOfClasses) \n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, input_size)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1) \n",
        "        return x\n",
        "\n",
        "model = Classifier()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f9sUALf9s_oz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbGHS7FAtCIT"
      },
      "outputs": [],
      "source": [
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() \n",
        "    for data, target in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        " \n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_MLP_model.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_MLP_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJzzfvtJZZDS"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vECtPm1oZbF6"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('CW_MLP_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YAFUzBfZehq"
      },
      "outputs": [],
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "\n",
        "    for i in range(5):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VqTBCfwtHMF"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eK4Ct5C71Df"
      },
      "outputs": [],
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULVhyRMG8ebo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "\n",
        "        self.fc2 = nn.Linear(500, number_classes) \n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzC3tWGG8wcB"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm0TBami86zG"
      },
      "outputs": [],
      "source": [
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_CNN_model.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_CNN_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0YSlaMU8-yE"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KET3rDfU9Dqr"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('CW_CNN_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "\n",
        "    for i in range(5):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "dNVsrMHHmUC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BAnUrKRtPMD"
      },
      "source": [
        "#TL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, numberOfClasses)\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "oV5Jw3eTOTAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr1)"
      ],
      "metadata": {
        "id": "kjsHFceGpZO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss_min = np.Inf\n",
        "\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() \n",
        "    for data, target in train_loader:\n",
        "\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in val_loader:\n",
        "\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'CW_resnet18_model_fine_tune_aug.pt')\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/CW_resnet18_model_fine_tune_aug.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "id": "YZUilYlzpbwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "id": "0ze50KwWpeL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('CW_resnet18_model_fine_tune_aug.pt'))"
      ],
      "metadata": {
        "id": "yJOHp7yHpgx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(5):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (class_total[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "OPYaqPYTppO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Coursework.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPL4T2UPYewXcwWpPIDJHv5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}